# Numerical Optimization 2025 - Project 1, Phase 2

**Deadline:** June 15, 2025, 23:59  
**Course:** Numerical Optimization 2025  
**Project Phase:** 1 â€“ Phase 2 (Group Work)

## ğŸ“Œ Overview

This repository contains our implementation for **Phase 2** of Project 1 in the Numerical Optimization 2025 course. The goal is to explore, implement, and compare various **Newton-like optimization methods** to solve a **nonlinear least squares problem** involving the approximation of the sine function using a sum of Gaussians.

The optimization task is defined by minimizing the following objective function:

```
f(x) = (1/2) * Î£_{j=1}^{m} (Ï•(x; a_j) - b_j)^2
```

where `b_j = sin(a_j)`, and `a_j` are 100 uniformly spaced points in the interval `[-2Ï€, 2Ï€]`.

The approximation function is:

```
Ï•(x; t) = Î£_{i=1}^{l} Î±_i * exp( - (t - Î¼_i)^2 / (2 * Ïƒ_i^2) )
```

with `l = 4`, and `x âˆˆ â„^{12}` (i.e., 3 parameters for each Gaussian).

---

## âš™ï¸ Implemented Methods

Each of the following Newton-like optimization methods has been implemented and tested:

1. **Newton Method with Hessian Modification (NM-HM)** â€“ based on Section 3.4 of Nocedal & Wright (NW)
2. **Gauss-Newton Method (GNM)** â€“ Section 10.3 of NW
3. **Quasi-Newton BFGS**
4. **Quasi-Newton DFP**
5. **Quasi-Newton SR1 within a Trust-Region Framework**
6. **Gauss-Newton-BFGS Hybrid** â€“ for large-residual problems (NW Section 10.3)

> All methods except SR1 are implemented in a **line-search framework** using **backtracking line search** with initial step size `Î±â‚€ = 1`.

---

## ğŸ“Š Experiments and Evaluation

Each method is tested on the same objective function and compared based on:

- **Stopping Criteria:** Gradient norm or maximum number of iterations
- **Convergence Behavior:** Using:
  - `â„“â‚– = ||xâ‚–â‚Šâ‚ - x*|| / ||xâ‚– - x*||`
  - `qâ‚– = ||xâ‚–â‚Šâ‚ - x*|| / ||xâ‚– - x*||Â²`
- **Function Approximation Quality:** Plot of `Ï•(ğ‘¥Ì„; t)` vs. `sin(t)`
- **Distance to Reference Solution:** `||ğ‘¥Ì„ âˆ’ x*||`
- **Performance Metrics:**
  - Global vs. local convergence behavior
  - Convergence rate (linear, superlinear, or quadratic)
  - Average runtime over multiple runs

---

## ğŸ“ EXAMPLE Repository Structure

```
â”œâ”€â”€ methods(part1)/
|   â”œâ”€â”€ 1-2_newton(David)/
â”‚     â”œâ”€â”€ newton_modified.py
â”‚     â”œâ”€â”€ gauss_newton.py
|     â”œâ”€â”€ run_nm_hm.py
â”‚     â”œâ”€â”€ run_gnm.py
â”‚     â”œâ”€â”€ results_nm_hm/
â”‚     â”œâ”€â”€ results_gnm/
|     â”œâ”€â”€ utils_nm/
|   â”œâ”€â”€ 3-5_quasinewton(Gergo)/
â”‚     â”œâ”€â”€ bfgs.py
|     â”œâ”€â”€ dfp.py
â”‚     â”œâ”€â”€ sr1_trust_region.py
â”‚     â”œâ”€â”€ run_bfgs.py
â”‚     â”œâ”€â”€ run_dfp.py
â”‚     â”œâ”€â”€ run_sr1.py
â”‚     â”œâ”€â”€ results_bfgs/
â”‚     â”œâ”€â”€ results_dfp/
â”‚     â”œâ”€â”€ results_sr1/
|     â”œâ”€â”€ utils_qn/
|   â””â”€â”€ 6_hybrid(Diego)/
â”‚     â”œâ”€â”€ gauss_newton_bfgs.py
â”‚     â”œâ”€â”€ run_gn_bfgs.py
â”‚     â”œâ”€â”€ results_gn_bfgs/
â”‚     â””â”€â”€ utils_hy/
â”‚
â”œâ”€â”€ comparison_experiments(part2)/
â”‚     â”œâ”€â”€ newton.py
â”‚     â”œâ”€â”€ run_experiments.py
â”‚     â”œâ”€â”€ results_experiments/
â”‚     â””â”€â”€ utils_experiments/
â”‚
â”œâ”€â”€ report/
â”‚   â””â”€â”€ Numerical_Optimization_Phase2_Report.pdf
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---


## ğŸ“ Report

The full analysis, methodology, graphs, and results discussion can be found in:

```
report/Numerical_Optimization_Phase2_Report.pdf
```

---

## ğŸ‘¥ Contributors

- David Klingbeil
- Diego Caparros Vaquer
- Gergely TerÃ©nyi
- Testimony Joshua Akpakwere
- (Tafara Zhande = Random)?

---
